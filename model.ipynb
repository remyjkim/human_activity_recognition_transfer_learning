{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"A-9KKm-iakKf","executionInfo":{"status":"ok","timestamp":1670457728700,"user_tz":300,"elapsed":5248,"user":{"displayName":"Andrew Raine","userId":"00646384938603451515"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","source":["class modelV1(nn.Module):\n","  def __init__(self, config):\n","    super(modelV1, self).__init__()\n","    self.lstm = nn.LSTM(23, 50, 1, batch_first=True)\n","    ffn_input_shape = self.computeShape(config.batch_size, config.sample_length)\n","    self.head = nn.Linear(ffn_input_shape, 13)\n","\n","  def forward(self, x):\n","    x, (c, h) = self.lstm(x)\n","    # print(x.shape)\n","    x = torch.flatten(x, start_dim=1)\n","    # print(x.shape)\n","    x = self.head(x)\n","    return x\n","\n","  def computeShape(self, batch_size, sample_length=8):\n","    'compute the flattened shape to FFN head'\n","    tens = torch.randn((batch_size, sample_length, 23))\n","    x, (c, h) = self.lstm(tens)\n","    return torch.flatten(x, start_dim=1).shape[1]"],"metadata":{"id":"33GseHspb3rS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ConvNet1D(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.layer1 = nn.Sequential(\n","            nn.Conv1d(23, 64, kernel_size=3),\n","            nn.ReLU(),\n","            nn.Dropout(0.5))\n","        self.layer2 = nn.Flatten()\n","        \n","        ffn_input_shape = self.computeShape(config.batch_size, config.sample_length)\n","\n","        self.layer3 = nn.Sequential(\n","            nn.Linear(ffn_input_shape,128),\n","            nn.ReLU())\n","        self.layer4 = nn.Sequential(\n","            nn.Linear(128,13),\n","            nn.Softmax())\n","        \n","        self.c = config\n","\n","    def forward(self, x):\n","        x = x.permute((0, 2, 1))\n","        out = self.layer1(x)\n","        out = self.layer2(out)\n","        out = self.layer3(out)\n","        out = self.layer4(out)\n","        return out\n","\n","    def computeShape(self, batch_size, sample_length=8):\n","      'compute the flattened shape to FFN head'\n","      tens = torch.randn((batch_size, 23, sample_length))\n","      x = self.layer1(tens)\n","      x = self.layer2(x)\n","      return x.shape[1]"],"metadata":{"id":"x9kI9WNDBg08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class MLP1(nn.Module):\n","#     def __init__(self,config):\n","#         super().__init__()\n","#         self.layers = nn.Sequential(\n","#             nn.Linear(16*23, 100),\n","#             nn.ReLU(),\n","#             nn.Linear(100, 30),\n","#             nn.ReLU(),\n","#             nn.Linear(30, 6)\n","#         )\n","\n","#     def forward(self, x):\n","#         x = x.view(x.size(0), -1)\n","#         x = self.layers(x)\n","#         return x\n","\n","\n","# class MLP1(nn.Module):\n","#     def __init__(self,config):\n","#         super().__init__()\n","#         self.conv_layers = nn.Sequential(\n","#             nn.Conv1d(16, 32, 5),\n","#             nn.ReLU(),\n","#             nn.Conv1d(32, 32, 5),\n","#             nn.ReLU(),\n","#             nn.Conv1d(32, 32, 5),\n","#             nn.ReLU(),\n","#             nn.Conv1d(32, 5, 5)\n","#         )\n","\n","#         self.linear_layers = nn.Sequential(\n","#             nn.Linear(35, 20),\n","#             nn.ReLU(),\n","#             nn.Linear(20, 10),\n","#             nn.ReLU(),\n","#             nn.Linear(10, 6),\n","#         )\n","\n","#     def forward(self, x):\n","#         x = self.conv_layers(x)\n","#         x = x.flatten(start_dim=1)\n","#         x = self.linear_layers(x)\n","#         return x\n","\n","\n","\n","class MLP1(nn.Module):\n","    def __init__(self,config):\n","        super().__init__()\n","        self.conv_layers = nn.Sequential(\n","            nn.Conv1d(16, 32, 5),\n","            nn.ReLU(),\n","            nn.Conv1d(32, 32, 5),\n","            nn.ReLU(),\n","            nn.Conv1d(32, 32, 5),\n","            nn.ReLU(),\n","            nn.Conv1d(32, 5, 5)\n","        )\n","\n","        self.linear_layers = nn.Sequential(\n","            nn.Linear(35, 20),\n","            nn.ReLU(),\n","            nn.Linear(20, 10),\n","            nn.ReLU(),\n","            nn.Linear(10, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.conv_layers(x)\n","        x = x.flatten(start_dim=1)\n","        x = self.linear_layers(x)\n","        return x"],"metadata":{"id":"3RxSJGUB7WY0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class MLP2(nn.Module):\n","#     def __init__(self, config):\n","#         super().__init__()\n","#         self.layers = nn.Sequential(\n","#             nn.Linear(16*6, 50),\n","#             nn.ReLU(),\n","#             nn.Linear(50, 30),\n","#             nn.ReLU(),\n","#             nn.Linear(30, 6),\n","#         )\n","        \n","#     def forward(self, x):\n","#         x = x.view(x.size(0), -1)\n","#         x = self.layers(x)\n","#         return x\n","\n","\n","\n","# class MLP2(nn.Module):\n","#     def __init__(self,config):\n","#         super().__init__()\n","#         self.conv_layers = nn.Sequential(\n","#             nn.Conv1d(16, 32, 2),\n","#             nn.ReLU(),\n","#             nn.Conv1d(32, 32, 2),\n","#             nn.ReLU(),\n","#             nn.Conv1d(32, 32, 2),\n","#             nn.ReLU(),\n","#             nn.Conv1d(32, 5, 2)\n","#         )\n","\n","#         self.linear_layers = nn.Sequential(\n","#             nn.Linear(10, 10),\n","#             nn.ReLU(),\n","#             nn.Linear(10, 10),\n","#             nn.ReLU(),\n","#             nn.Linear(10, 6),\n","#         )\n","\n","#     def forward(self, x):\n","#         x = self.conv_layers(x)\n","#         x = x.flatten(start_dim=1)\n","#         x = self.linear_layers(x)\n","#         return x\n","\n","\n","class MLP2(nn.Module):\n","    def __init__(self,config):\n","        super().__init__()\n","        self.layers = nn.Sequential(\n","            nn.Flatten(start_dim=1),\n","            nn.Linear(96, 80),\n","            nn.ReLU(),\n","            nn.Linear(80, 60),\n","            nn.ReLU(),\n","            nn.Linear(60, 40),\n","            nn.ReLU(),\n","            nn.Linear(40, 20),\n","            nn.ReLU(),\n","            nn.Linear(20, 10),\n","        )\n","\n","    def forward(self, x):\n","        x = self.layers(x)\n","        return x\n","\n","# ml2 = MLP2(None)\n","\n","# tens = torch.randn((32, 16, 6))\n","\n","# ml2(tens)"],"metadata":{"id":"PF2EnGL9TEdH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# class MLP3(nn.Module):\n","#     def __init__(self,config):\n","#         super().__init__()\n","#         self.classifier = nn.Sequential(\n","#             nn.Linear(6, 6),\n","#             nn.ReLU(),\n","#             nn.Linear(6, 6),\n","#             nn.ReLU(),\n","#             nn.Linear(6, 6)\n","#         )\n","\n","#     def forward(self, x):\n","#         x = self.classifier(x)\n","#         return x\n","\n","# class MLP3(nn.Module):\n","#     def __init__(self,config):\n","#         super().__init__()\n","#         self.classifier = nn.Sequential(\n","#             nn.Linear(96, 30),\n","#             nn.ReLU(),\n","#             nn.Linear(30, 30),\n","#             nn.ReLU(),\n","#             nn.Linear(30, 6),\n","#         )\n","\n","#     def forward(self, x):\n","#         x = x.view(x.size(0), -1)\n","#         x = self.classifier(x)\n","#         return x\n","\n","\n","class MLP3(nn.Module):\n","    def __init__(self,config):\n","        super().__init__()\n","        self.classifier = nn.Sequential(\n","            nn.Linear(10, 10),\n","            nn.ReLU(),\n","            nn.Linear(10, 10),\n","            nn.ReLU(),\n","            nn.Linear(10, 6)\n","        )\n","\n","    def forward(self, x):\n","        x = self.classifier(x)\n","        return x"],"metadata":{"id":"TSeulRa2CGsD"},"execution_count":null,"outputs":[]}]}